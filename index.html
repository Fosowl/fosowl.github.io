<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Martin Legrand - Portfolio</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <div class="terminal">
        <div class="terminal-header">
            <span class="button close"></span>
            <span class="button minimize"></span>
            <span class="button maximize"></span>
            <span class="title">Martin Legrand - Portfolio</span>
        </div>
        <div class="terminal-body">
            <header>
                <h1>Martin Legrand</h1>
                <p>Machine Learning Engineer specializing in Audio Recognition / ASR and Natural Language Processing (NLP/LLMs)</p>
            </header>
            <main>
                <section>
                    <h2>$ education</h2>
                    <br>
                    <h3>Epitech (2019 - 2024)</h3>
                    <p>Master of Computer Science</p>
                    <ul>
                        <li>Learning computer science from the fundamentals (C, C++), Python, Web & Mobile frameworks.</li>
                        <li>Project-based methodology, often carried out in groups.</li>
                        <li>Specialization in AI in the 4th and 5th years.</li>
                    </ul>
                    <br>
                    <h3>造甲大學 Feng Chia University (2022 - 2023)</h3>
                    <p>Study year in Taiwan.</p>
                    <ul>
                        <li>Courses in Computer Vision, Optimization, Optimal Control, NLP Algorithms, and AI for E-commerce.</li>
                        <li>Familiarity with key AI players, such as TSMC, a leader in GPU chip manufacturing.</li>
                        <li>Knowledge of the Asian market.</li>
                    </ul>
                </section>
                <section>
                    <h2>$ projects</h2>
                    <ul>
                        <li>
                            <a href="https://github.com/Fosowl/agenticSeek" target="_blank" rel="noopener noreferrer">Jarvis like AI assistant</a>: 
                            This project aim to create an AI assistant that can perform a wide range of tasks. Using swarm of deepseek agents.
                            It can browse the web, conqueer and divide tasks and execute code in many languages and use Bash to control the user system.
                            With its interpreter it detects and fixes errors autonomously. A built-in routing system selects the best agent for each task, optimizing performance.
                            Fast text-to-speech and speech-to-text ensures seamless interaction, while memory compression efficiently manages long sessions.
                        </li>
                        <br>
                        <li>
                            <a href="https://github.com/Fosowl/MonocularSLAM" target="_blank" rel="noopener noreferrer">MonocularSLAM</a>: 
                            Implementation of Simultaneous Localization and Mapping (SLAM) algorithms using OpenCV. 
                            This project focused on enabling a single camera (monocular vision) to map an environment while tracking its own position. 
                            Utilized Python and OpenCV to process video frames, extract features, and reconstruct 3D scenes in real-time, 
                            showcasing applications in robotics and augmented reality.
                        </li>
                        <br>
                        <li>
                            <a href="https://github.com/Fosowl/SoundGAN" target="_blank" rel="noopener noreferrer">SoundGAN</a>: 
                            Developed a Generative Adversarial Network (GAN) for synthetic sound generation in PyTorch.
                            The project explored the use of deep learning to create audio samples, such as environmental sounds or musical tones, 
                            by training a generator and discriminator on audio datasets. It come with a full pipeline for sound acquisition and processing.
                        </li>
                        <br>
                        <li>
                            <a href="https://github.com/Fosowl/ReinforcementLearningGym" target="_blank" rel="noopener noreferrer">ReinforcementLearningGym</a>: 
                            Designed a suite of reinforcement learning (RL) experiments to navigate OpenAI Gym environments. 
                            Solved classic RL problems like cart-pole balancing, moon lander and walker with Q-learning and deep Q-networks (DQN). 
                        </li>
                        <br>
                        <li>
                            <a href="https://github.com/Fosowl/WoodetectChatbot" target="_blank" rel="noopener noreferrer">WoodetectChatbot</a>: 
                            Built a conversational chatbot as part of the Woodetect project website, finetuned for our specific needs. 
                        </li>
                    </ul>
                    <h2>$ publication</h2>
                    <br>
                    <li>
                        <a href="https://medium.com/@mlg.fcu" target="_blank" rel="noopener noreferrer">Medium articles</a>: 
                        Authoring of technical write-ups documenting my AI projects and insights. 
                        Covered topics such as NLP algorithms, audio processing with CNNs, and optimization techniques learned during my studies in Taiwan. 
                    </li>
                    <ul>
                    </ul>
                </section>
                <section>
                    <h2>$ experience</h2>
                    <br>
                    <h3>AI Research Engineer - Alten (03/2024 - 08/2024)</h3>
                    <p>Rennes, France</p>
                    <ul>
                        <li>Research project on a solution leveraging LLMs for voice command of autonomous agents in multi-agent systems.</li>
                        <li>Contribution to a research topic aimed at improving the performance of small-scale LLMs (1B to 7B) in slot filling. Achieved a 15-20% performance improvement on a voice instruction dataset.</li>
                        <li>Conducted experiments and authored an internal research document.</li>
                    </ul>
                    <br>
                    <h3>Machine Learning Engineer - Woodetect (01/2022 - 01/2024)</h3>
                    <p>France/Taiwan (remote)</p>
                    <ul>
                        <li>AI & Machine Learning developer for the Woodetect study project as part of the Epitech Innovative Project.</li>
                        <li>Developed a sound analysis system using Convolutional Neural Networks (CNN) with PyTorch.</li>
                        <li>Built a pipeline for sound acquisition and processing.</li>
                        <li>Worked in a team of 9 members across different time zones.</li>
                        <li>Developed a chatbot using Llama 2.</li>
                    </ul>
                    <br>
                    <h3>Flutter Developer - Grsentiers (03/2022 - 08/2022)</h3>
                    <p>Bruxelles, Belgium</p>
                    <ul>
                        <li>Developer at Grsentiers, designing a mobile application in Flutter.</li>
                    </ul>
                    <br>
                    <h3>DevOps Engineer - CNRS (10/2021 - 02/2022)</h3>
                    <p>Toulouse, France</p>
                    <ul>
                        <li>Developer at the Laero laboratory of CNRS, setting up a Yocto DevOps compilation pipeline for an airborne pollution measurement project (IAGOS project).</li>
                        <li>Automated the compilation of the operating system and embedded software through a CI/CD pipeline with Gitlab.</li>
                        <li>Created a custom Yocto distribution tailored to the requirements of embedded hardware.</li>
                    </ul>
                </section>
                <section>
                    <h2>$ tech_stack</h2>
                    <br>
                    <ul>
                        <li>Language: Python, C/C++, Golang, C#, R, CUDA</li>
                        <li>Framework ML: Pytorch, Tensorflow, Transformers, Keras, Numpy, Hugging-Face</li>
                        <li>Devops: Gitlab, Github, Docker, MLflow, AWS</li>
                    </ul>
                </section>
                <section>
                    <h2>$ contact</h2>
                    <br>
                    <p>Open to contract. Feel free to contact me for any inquiries.</p>
                    <br>
                    <p>Email: <a href="mailto:martin.legrand@epitech.eu">martin.legrand@epitech.eu</a></p>
                    <p>Telegram: +33 06 03 98 60 75</p>
                    <p>GitHub: <a href="https://github.com/Fosowl" target="_blank" rel="noopener noreferrer">https://github.com/Fosowl</a></p>
                    <p>Location: Toulouse, France</p>
                    <p>Languages: English, French, Chinese</p>
                </section>
            </main>
            <footer>
                <p>martin_legrand@portfolio:~$ exit</p>
            </footer>
        </div>
    </div>
</body>
</html>
